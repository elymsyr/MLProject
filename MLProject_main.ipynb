{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jydQTw71rlIl",
        "-Tssi5gl7fIh",
        "U0CAJK_t7pbw",
        "rGoYOliVTfxh",
        "Yw6O7m-UTnJp"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM0x5O+zRORIf6dXzBUf/ny",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elymsyr/MLProject/blob/main/MLProject_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Environment"
      ],
      "metadata": {
        "id": "rhZLlCW3iZBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/sample_data"
      ],
      "metadata": {
        "id": "JqHMB_sc6aT-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cuda Downgrade"
      ],
      "metadata": {
        "id": "ylB_bZSvbOdz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxHtkoGOHUV5"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get purge \"cuda*\"\n",
        "!rm -rf /usr/local/cuda*\n",
        "!sudo apt-get autoremove\n",
        "!sudo apt-get autoclean"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "s9UMlY9ULU65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install other import packages\n",
        "!sudo apt-get install g++ freeglut3-dev build-essential libx11-dev \\\n",
        "    libxmu-dev libxi-dev libglu1-mesa libglu1-mesa-dev"
      ],
      "metadata": {
        "id": "HDMy3Zzmucjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin\n",
        "!sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda-repo-ubuntu2204-11-8-local_11.8.0-520.61.05-1_amd64.deb\n",
        "!sudo dpkg -i cuda-repo-ubuntu2204-11-8-local_11.8.0-520.61.05-1_amd64.deb\n",
        "!sudo cp /var/cuda-repo-ubuntu2204-11-8-local/cuda-*-keyring.gpg /usr/share/keyrings/\n",
        "!sudo apt-get update\n",
        "!sudo apt-get -y install cuda-11.8"
      ],
      "metadata": {
        "id": "n3R-hJUAMzp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(1, \"/usr/local/cuda-11.8/lib64\")\n",
        "sys.path.insert(1, \"/usr/local/cuda-11.8/bin\")"
      ],
      "metadata": {
        "id": "k3kD6rVx0GJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo 'export PATH=/usr/local/cuda-11.8/bin:$PATH' >> ~/.bashrc\n",
        "!echo 'export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc\n",
        "!source ~/.bashrc"
      ],
      "metadata": {
        "id": "JAHb0AkvM3Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r /usr/local/cuda-xxx/lib64/libcudnn*"
      ],
      "metadata": {
        "id": "tlbpHORdwAU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo wget https://developer.download.nvidia.com/compute/redist/cudnn/v8.6.0/local_installers/11.8/cudnn-linux-x86_64-8.6.0.163_cuda11-archive.tar.xz\n",
        "!sudo tar -xvf /content/cudnn-linux-x86_64-8.6.0.163_cuda11-archive.tar.xz\n",
        "!sudo mv /content/cudnn-linux-x86_64-8.6.0.163_cuda11-archive cuda\n",
        "\n",
        "# copy the following files into the cuda toolkit directory.\n",
        "!sudo cp -P cuda/include/cudnn.h /usr/local/cuda-11.8/include\n",
        "!sudo cp -P cuda/lib/libcudnn* /usr/local/cuda-11.8/lib64/\n",
        "!sudo chmod a+r /usr/local/cuda-11.8/lib64/libcudnn*\n",
        "\n",
        "# Finally, to verify the installation, check\n",
        "!nvidia-smi\n",
        "!nvcc -V"
      ],
      "metadata": {
        "id": "SatYiSBJppf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "id": "v73JeIt80uUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Check if GPU is available\n",
        "!nvcc --version\n",
        "!nvidia-smi\n",
        "if torch.cuda.is_available():\n",
        "    torch.set_default_device('cuda')\n",
        "    # Get the number of available GPUs\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    if num_gpus > 0:\n",
        "        print(f\"Number of available GPU devices: {num_gpus}\")\n",
        "        # Iterate over available GPUs and print their index and name\n",
        "        for gpu_index in range(num_gpus):\n",
        "            gpu_name = torch.cuda.get_device_name(gpu_index)\n",
        "            print(f\"GPU {gpu_index}: {gpu_name}\")\n",
        "    else:\n",
        "        print(\"No GPU devices available.\")\n",
        "else:\n",
        "    print(\"GPU is not available.\")"
      ],
      "metadata": {
        "id": "HAPC43s3wMHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /usr/src/cudnn_samples_v8/ $HOME\n",
        "! cd  $HOME/cudnn_samples_v8/mnistCUDNN\n",
        "!make clean && make\n",
        "! ./mnistCUDNN"
      ],
      "metadata": {
        "id": "YqvkFWehZWs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "XUHpwc72aI51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Python Version and Packages"
      ],
      "metadata": {
        "id": "5iOfth00ibKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-KnehGu6Czy",
        "outputId": "ed2d03e2-896b-4736-a224-5ad03bdbfc10"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downgrade the python version to v3.9. Install necessary packages. You can find it on [github.com/elymsyr/MLProject](https://github.com/elymsyr/MLProject) (/Docs/requirements.txt)"
      ],
      "metadata": {
        "id": "Qf9eFFFWcwof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.9\n",
        "\n",
        "#change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1\n",
        "\n",
        "#check python version\n",
        "!python --version\n",
        "\n",
        "# install pip for new python\n",
        "!sudo apt-get install python3.9-distutils\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "!python get-pip.py\n",
        "\n",
        "# install colab's dependencies\n",
        "!python -m pip install ipython tensorflow==2.13.0 tensorboard ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor\n",
        "\n",
        "# link to the old google package\n",
        "!ln -s /usr/local/lib/python3.9/dist-packages/google\n",
        "\n",
        "# Change between versions\n",
        "# !sudo update-alternatives --config python3 <RowNumber>\n",
        "\n",
        "!python --version"
      ],
      "metadata": {
        "id": "wzPbOvSDmOlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install --upgrade pip\n",
        "!pip install --upgrade setuptools pip wheel\n",
        "!pip install mlagents==0.30.0\n",
        "!pip install mlagents-envs==0.30.0"
      ],
      "metadata": {
        "id": "Ke_8hbCjhC8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "id": "38Y3m_gipliD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "1x1v4fG77535",
        "outputId": "c35a4cb3-2bb6-4be4-9cdc-1ecb9fb4daa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.2.1-cp39-cp39-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
            "Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, jinja2, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0\n",
            "    Uninstalling torch-1.11.0:\n",
            "      Successfully uninstalled torch-1.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mlagents 0.30.0 requires torch<=1.11.0,>=1.8.0; platform_system != \"Windows\" and python_version >= \"3.9\", but you have torch 2.2.1 which is incompatible.\n",
            "tensorflow 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.21.2 which is incompatible.\n",
            "tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2024.2.0 jinja2-3.1.3 mpmath-1.3.0 networkx-3.2.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 sympy-1.12 torch-2.2.1 torchaudio-2.2.1 torchvision-0.17.1 triton-2.2.0 typing-extensions-4.10.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvidia-pyindex\n",
        "# !pip install --upgrade nvidia-tensorrt"
      ],
      "metadata": {
        "id": "aLrC1yVnG3Hj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39fb36db-e062-4164-90cf-921b244d9a6f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-pyindex\n",
            "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvidia-pyindex\n",
            "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8419 sha256=d0bab891f870c9742705ffd1080d756333edcdbd4176e2b933881ea42f2a264a\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/63/71/c50214b560fa8c319598c2de3c1616f6d68e1d2c7f17a5e82d\n",
            "Successfully built nvidia-pyindex\n",
            "Installing collected packages: nvidia-pyindex\n",
            "Successfully installed nvidia-pyindex-1.0.9\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip protobuf==3.20.3 install numpy==1.23.5 onnx==1.15.0"
      ],
      "metadata": {
        "id": "bYDF5ZkU8I9g",
        "outputId": "1e432148-f3a5-4ef9-cc93-ea8bfb26cb9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting onnx==1.12.0\n",
            "  Downloading onnx-1.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting protobuf<=3.20.1,>=3.12.2 (from onnx==1.12.0)\n",
            "  Downloading protobuf-3.20.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (698 bytes)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx==1.12.0) (4.10.0)\n",
            "Downloading numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, numpy, onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.3\n",
            "    Uninstalling protobuf-4.25.3:\n",
            "      Successfully uninstalled protobuf-4.25.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.2\n",
            "    Uninstalling numpy-1.21.2:\n",
            "      Successfully uninstalled numpy-1.21.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mlagents 0.30.0 requires torch<=1.11.0,>=1.8.0; platform_system != \"Windows\" and python_version >= \"3.9\", but you have torch 2.2.1 which is incompatible.\n",
            "mlagents-envs 0.30.0 requires numpy==1.21.2, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5 onnx-1.12.0 protobuf-3.20.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Environment"
      ],
      "metadata": {
        "id": "xSFmvS2AWmTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Tensorflow-Pytorch GPU"
      ],
      "metadata": {
        "id": "IzJBP6GxdXJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !ln -s /usr/local/lib/python3.9/dist-packages/tensorrt_libs/libnvinfer.so.8 /usr/lib64-nvidia/libnvinfer.so.7\n",
        "# !ln -s /usr/local/lib/python3.9/dist-packages/tensorrt_libs/libnvinfer_plugin.so.8 /usr/lib64-nvidia/libnvinfer_plugin.so.7\n",
        "# !ln -s /usr/local/cuda-12.2/targets/x86_64-linux/lib/libcudart.so.12 /usr/lib64-nvidia/libcudart.so.11.0"
      ],
      "metadata": {
        "id": "1vEdkOT0cqoU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "# for device in gpu_devices:\n",
        "#     tf.config.experimental.set_memory_growth(device, True)"
      ],
      "metadata": {
        "id": "lZ75KHZH6Mfk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "id": "iuAc13Vc5rYs",
        "outputId": "dd1c9351-badc-46dc-f504-8f6065283bf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Old way (deprecated)\n",
        "# torch.set_default_tensor_type(torch.FloatTensor)\n",
        "\n",
        "# New way\n",
        "torch.set_default_dtype(torch.float32)\n",
        "torch.set_default_device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "sH8bNeh_Agj_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Check if GPU is available\n",
        "!nvcc --version\n",
        "!nvidia-smi\n",
        "if torch.cuda.is_available():\n",
        "    torch.set_default_device('cuda')\n",
        "    # Get the number of available GPUs\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    if num_gpus > 0:\n",
        "        print(f\"Number of available GPU devices: {num_gpus}\")\n",
        "        # Iterate over available GPUs and print their index and name\n",
        "        for gpu_index in range(num_gpus):\n",
        "            gpu_name = torch.cuda.get_device_name(gpu_index)\n",
        "            print(f\"GPU {gpu_index}: {gpu_name}\")\n",
        "    else:\n",
        "        print(\"No GPU devices available.\")\n",
        "else:\n",
        "    print(\"GPU is not available.\")"
      ],
      "metadata": {
        "id": "GnZuyr3ClOQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc47c89-d6d6-4c9c-ffbd-9e2404f45da3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Wed Mar 13 22:55:35 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Number of available GPU devices: 1\n",
            "GPU 0: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test MLAgents"
      ],
      "metadata": {
        "id": "jydQTw71rlIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-learn -h"
      ],
      "metadata": {
        "id": "GW5cCfHAiRYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8992ca41-26a7-499c-9cf6-8075beda481b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "2024-03-13 22:55:37.836131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "usage: mlagents-learn [-h] [--env ENV_PATH] [--resume] [--deterministic] [--force]\n",
            "                      [--run-id RUN_ID] [--initialize-from RUN_ID] [--seed SEED] [--inference]\n",
            "                      [--base-port BASE_PORT] [--num-envs NUM_ENVS] [--num-areas NUM_AREAS]\n",
            "                      [--debug] [--env-args ...] [--max-lifetime-restarts MAX_LIFETIME_RESTARTS]\n",
            "                      [--restarts-rate-limit-n RESTARTS_RATE_LIMIT_N]\n",
            "                      [--restarts-rate-limit-period-s RESTARTS_RATE_LIMIT_PERIOD_S] [--torch]\n",
            "                      [--tensorflow] [--results-dir RESULTS_DIR] [--width WIDTH] [--height HEIGHT]\n",
            "                      [--quality-level QUALITY_LEVEL] [--time-scale TIME_SCALE]\n",
            "                      [--target-frame-rate TARGET_FRAME_RATE]\n",
            "                      [--capture-frame-rate CAPTURE_FRAME_RATE] [--no-graphics]\n",
            "                      [--torch-device DEVICE]\n",
            "                      [trainer_config_path]\n",
            "\n",
            "positional arguments:\n",
            "  trainer_config_path\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --env ENV_PATH        Path to the Unity executable to train (default: None)\n",
            "  --resume              Whether to resume training from a checkpoint. Specify a --run-id to use\n",
            "                        this option. If set, the training code loads an already trained model to\n",
            "                        initialize the neural network before resuming training. This option is\n",
            "                        only valid when the models exist, and have the same behavior names as the\n",
            "                        current agents in your scene. (default: False)\n",
            "  --deterministic       Whether to select actions deterministically in policy. `dist.mean` for\n",
            "                        continuous action space, and `dist.argmax` for deterministic action space\n",
            "                        (default: False)\n",
            "  --force               Whether to force-overwrite this run-id's existing summary and model data.\n",
            "                        (Without this flag, attempting to train a model with a run-id that has\n",
            "                        been used before will throw an error. (default: False)\n",
            "  --run-id RUN_ID       The identifier for the training run. This identifier is used to name the\n",
            "                        subdirectories in which the trained model and summary statistics are saved\n",
            "                        as well as the saved model itself. If you use TensorBoard to view the\n",
            "                        training statistics, always set a unique run-id for each training run.\n",
            "                        (The statistics for all runs with the same id are combined as if they were\n",
            "                        produced by a the same session.) (default: ppo)\n",
            "  --initialize-from RUN_ID\n",
            "                        Specify a previously saved run ID from which to initialize the model from.\n",
            "                        This can be used, for instance, to fine-tune an existing model on a new\n",
            "                        environment. Note that the previously saved models must have the same\n",
            "                        behavior parameters as your current environment. (default: None)\n",
            "  --seed SEED           A number to use as a seed for the random number generator used by the\n",
            "                        training code (default: -1)\n",
            "  --inference           Whether to run in Python inference mode (i.e. no training). Use with\n",
            "                        --resume to load a model trained with an existing run ID. (default: False)\n",
            "  --base-port BASE_PORT\n",
            "                        The starting port for environment communication. Each concurrent Unity\n",
            "                        environment instance will get assigned a port sequentially, starting from\n",
            "                        the base-port. Each instance will use the port (base_port + worker_id),\n",
            "                        where the worker_id is sequential IDs given to each instance from 0 to\n",
            "                        (num_envs - 1). Note that when training using the Editor rather than an\n",
            "                        executable, the base port will be ignored. (default: 5005)\n",
            "  --num-envs NUM_ENVS   The number of concurrent Unity environment instances to collect\n",
            "                        experiences from when training (default: 1)\n",
            "  --num-areas NUM_AREAS\n",
            "                        The number of parallel training areas in each Unity environment instance.\n",
            "                        (default: 1)\n",
            "  --debug               Whether to enable debug-level logging for some parts of the code (default:\n",
            "                        False)\n",
            "  --env-args ...        Arguments passed to the Unity executable. Be aware that the standalone\n",
            "                        build will also process these as Unity Command Line Arguments. You should\n",
            "                        choose different argument names if you want to create environment-specific\n",
            "                        arguments. All arguments after this flag will be passed to the executable.\n",
            "                        (default: None)\n",
            "  --max-lifetime-restarts MAX_LIFETIME_RESTARTS\n",
            "                        The max number of times a single Unity executable can crash over its\n",
            "                        lifetime before ml-agents exits. Can be set to -1 if no limit is desired.\n",
            "                        (default: 10)\n",
            "  --restarts-rate-limit-n RESTARTS_RATE_LIMIT_N\n",
            "                        The maximum number of times a single Unity executable can crash over a\n",
            "                        period of time (period set in restarts-rate-limit-period-s). Can be set to\n",
            "                        -1 to not use rate limiting with restarts. (default: 1)\n",
            "  --restarts-rate-limit-period-s RESTARTS_RATE_LIMIT_PERIOD_S\n",
            "                        The period of time --restarts-rate-limit-n applies to. (default: 60)\n",
            "  --torch               (Removed) Use the PyTorch framework. (default: False)\n",
            "  --tensorflow          (Removed) Use the TensorFlow framework. (default: False)\n",
            "  --results-dir RESULTS_DIR\n",
            "                        Results base directory (default: results)\n",
            "\n",
            "Engine Configuration:\n",
            "  --width WIDTH         The width of the executable window of the environment(s) in pixels\n",
            "                        (ignored for editor training). (default: 84)\n",
            "  --height HEIGHT       The height of the executable window of the environment(s) in pixels\n",
            "                        (ignored for editor training) (default: 84)\n",
            "  --quality-level QUALITY_LEVEL\n",
            "                        The quality level of the environment(s). Equivalent to calling\n",
            "                        QualitySettings.SetQualityLevel in Unity. (default: 5)\n",
            "  --time-scale TIME_SCALE\n",
            "                        The time scale of the Unity environment(s). Equivalent to setting\n",
            "                        Time.timeScale in Unity. (default: 20)\n",
            "  --target-frame-rate TARGET_FRAME_RATE\n",
            "                        The target frame rate of the Unity environment(s). Equivalent to setting\n",
            "                        Application.targetFrameRate in Unity. (default: -1)\n",
            "  --capture-frame-rate CAPTURE_FRAME_RATE\n",
            "                        The capture frame rate of the Unity environment(s). Equivalent to setting\n",
            "                        Time.captureFramerate in Unity. (default: 60)\n",
            "  --no-graphics         Whether to run the Unity executable in no-graphics mode (i.e. without\n",
            "                        initializing the graphics driver. Use this only if your agents don't use\n",
            "                        visual observations. (default: False)\n",
            "\n",
            "Torch Configuration:\n",
            "  --torch-device DEVICE\n",
            "                        Settings for the default torch.device used in training, for example,\n",
            "                        \"cpu\", \"cuda\", or \"cuda:0\" (default: None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Build"
      ],
      "metadata": {
        "id": "-Tssi5gl7fIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --branch main https://github.com/elymsyr/colabMLAgetns.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEa2Kj4G6WZ-",
        "outputId": "2d65eb34-8c04-4fac-88d0-7050e9f21a28"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'colabMLAgetns'...\n",
            "remote: Enumerating objects: 211, done.\u001b[K\n",
            "remote: Total 211 (delta 0), reused 0 (delta 0), pack-reused 211\u001b[K\n",
            "Receiving objects: 100% (211/211), 63.55 MiB | 21.33 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "Updating files: 100% (455/455), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the permissions\n",
        "!chmod -R 755 /content/colabMLAgetns/b0.4.0/env3period5b040.x86_64\n",
        "!chmod -R 755 /content/colabMLAgetns/b0.4.0/UnityPlayer.so\n",
        "!ls -l /content/colabMLAgetns/b0.4.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53mAtnX76kw3",
        "outputId": "348d47af-835e-4e75-a6d7-b3d9fd18867e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 112816\n",
            "drwxr-xr-x 3 root root     4096 Mar 13 22:56 env3period5b040_BurstDebugInformation_DoNotShip\n",
            "drwxr-xr-x 6 root root     4096 Mar 13 22:56 env3period5b040_Data\n",
            "-rw-r--r-- 1 root root    16208 Mar 13 22:56 env3period5b040_s.debug\n",
            "-rwxr-xr-x 1 root root    15096 Mar 13 22:56 env3period5b040.x86_64\n",
            "-rw-r--r-- 1 root root 67164248 Mar 13 22:56 UnityPlayer_s.debug\n",
            "-rwxr-xr-x 1 root root 48314296 Mar 13 22:56 UnityPlayer.so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create config.yaml"
      ],
      "metadata": {
        "id": "U0CAJK_t7pbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.yaml\n",
        "\n",
        "default_settings: null\n",
        "behaviors:\n",
        "  AgentBehavior:\n",
        "    trainer_type: ppo\n",
        "    hyperparameters:\n",
        "      batch_size: 1024\n",
        "      buffer_size: 10240\n",
        "      learning_rate: 0.0003\n",
        "      beta: 0.005\n",
        "      epsilon: 0.2\n",
        "      lambd: 0.95\n",
        "      num_epoch: 3\n",
        "      shared_critic: false\n",
        "      learning_rate_schedule: linear\n",
        "      beta_schedule: linear\n",
        "      epsilon_schedule: linear\n",
        "    network_settings:\n",
        "      normalize: false\n",
        "      hidden_units: 256\n",
        "      num_layers: 3\n",
        "      vis_encode_type: simple\n",
        "      memory: null\n",
        "      goal_conditioning_type: hyper\n",
        "      deterministic: false\n",
        "    reward_signals:\n",
        "      extrinsic:\n",
        "        gamma: 0.99\n",
        "        strength: 1.0\n",
        "        network_settings:\n",
        "          normalize: false\n",
        "          hidden_units: 256\n",
        "          num_layers: 3\n",
        "          vis_encode_type: simple\n",
        "          memory: null\n",
        "          goal_conditioning_type: hyper\n",
        "          deterministic: false\n",
        "    init_path: null\n",
        "    keep_checkpoints: 5\n",
        "    checkpoint_interval: 500000\n",
        "    max_steps: 10000000\n",
        "    time_horizon: 64\n",
        "    summary_freq: 10000\n",
        "    threaded: false\n",
        "    self_play: null\n",
        "    behavioral_cloning: null\n",
        "env_settings:\n",
        "  env_path: /content/colabMLAgetns/b0.4.0/env3period5b040.x86_64\n",
        "  env_args: null\n",
        "  base_port: 5004\n",
        "  num_envs: 3\n",
        "  num_areas: 1\n",
        "  seed: -1\n",
        "  max_lifetime_restarts: 10\n",
        "  restarts_rate_limit_n: 1\n",
        "  restarts_rate_limit_period_s: 60\n",
        "engine_settings:\n",
        "  width: 84\n",
        "  height: 84\n",
        "  quality_level: 5\n",
        "  time_scale: 20.0\n",
        "  target_frame_rate: -1\n",
        "  capture_frame_rate: 60\n",
        "  no_graphics: true\n",
        "environment_parameters: null\n",
        "checkpoint_settings:\n",
        "  run_id: ColabTest\n",
        "  initialize_from:\n",
        "  load_model: false\n",
        "  resume: false\n",
        "  force: false\n",
        "  train_model: false\n",
        "  inference: false\n",
        "  results_dir: results\n",
        "torch_settings:\n",
        "  device: cuda\n",
        "debug: false"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyVmeCgc6sUG",
        "outputId": "bf66a934-7d4e-479a-8a51-0f258ee479eb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tenserboard and Train Process"
      ],
      "metadata": {
        "id": "9IL5Pm_s-O2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorboard"
      ],
      "metadata": {
        "id": "rGoYOliVTfxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir results\n",
        "%reload_ext tensorboard"
      ],
      "metadata": {
        "id": "WwITCL-w-RNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delete previous trains"
      ],
      "metadata": {
        "id": "Yw6O7m-UTnJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/results # if necessary"
      ],
      "metadata": {
        "id": "u6VC2WGfRyR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "Lj7Q4BsrTkkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-learn /content/config.yaml --env /content/colabMLAgetns/headless3/v033.x86_64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dZ7p5Pw7Yey",
        "outputId": "002ac11e-9381-4b2a-cc7b-7fdf0ab32ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "2024-03-13 22:58:50.732128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "            ┐  ╖\n",
            "        ╓╖╬│╡  ││╬╖╖\n",
            "    ╓╖╬│││││┘  ╬│││││╬╖\n",
            " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
            " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
            " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
            " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
            " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
            " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
            " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
            "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
            "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
            "          ╙╬╬╬╣╣╣╜\n",
            "             ╙\n",
            "        \n",
            " Version information:\n",
            "  ml-agents: 0.30.0,\n",
            "  ml-agents-envs: 0.30.0,\n",
            "  Communicator API: 1.5.0,\n",
            "  PyTorch: 2.2.1+cu121\n",
            "[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0\n",
            "[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0\n",
            "[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0\n",
            "[INFO] Connected new brain: AgentBehavior?team=0\n",
            "[INFO] Connected new brain: AgentBehavior?team=0\n",
            "[INFO] Connected new brain: AgentBehavior?team=0\n",
            "[INFO] Hyperparameters for behavior name AgentBehavior: \n",
            "\ttrainer_type:\tppo\n",
            "\thyperparameters:\t\n",
            "\t  batch_size:\t1024\n",
            "\t  buffer_size:\t10240\n",
            "\t  learning_rate:\t0.0003\n",
            "\t  beta:\t0.005\n",
            "\t  epsilon:\t0.2\n",
            "\t  lambd:\t0.95\n",
            "\t  num_epoch:\t3\n",
            "\t  shared_critic:\tFalse\n",
            "\t  learning_rate_schedule:\tlinear\n",
            "\t  beta_schedule:\tlinear\n",
            "\t  epsilon_schedule:\tlinear\n",
            "\tnetwork_settings:\t\n",
            "\t  normalize:\tFalse\n",
            "\t  hidden_units:\t256\n",
            "\t  num_layers:\t3\n",
            "\t  vis_encode_type:\tsimple\n",
            "\t  memory:\tNone\n",
            "\t  goal_conditioning_type:\thyper\n",
            "\t  deterministic:\tFalse\n",
            "\treward_signals:\t\n",
            "\t  extrinsic:\t\n",
            "\t    gamma:\t0.99\n",
            "\t    strength:\t1.0\n",
            "\t    network_settings:\t\n",
            "\t      normalize:\tFalse\n",
            "\t      hidden_units:\t256\n",
            "\t      num_layers:\t3\n",
            "\t      vis_encode_type:\tsimple\n",
            "\t      memory:\tNone\n",
            "\t      goal_conditioning_type:\thyper\n",
            "\t      deterministic:\tFalse\n",
            "\tinit_path:\tNone\n",
            "\tkeep_checkpoints:\t5\n",
            "\tcheckpoint_interval:\t500000\n",
            "\tmax_steps:\t10000000\n",
            "\ttime_horizon:\t64\n",
            "\tsummary_freq:\t10000\n",
            "\tthreaded:\tFalse\n",
            "\tself_play:\tNone\n",
            "\tbehavioral_cloning:\tNone\n",
            "[INFO] AgentBehavior. Step: 10000. Time Elapsed: 56.439 s. Mean Reward: -11.329. Std of Reward: 5.623. Training.\n",
            "[INFO] AgentBehavior. Step: 20000. Time Elapsed: 111.339 s. Mean Reward: -10.016. Std of Reward: 9.491. Training.\n",
            "[INFO] AgentBehavior. Step: 30000. Time Elapsed: 164.450 s. Mean Reward: -11.290. Std of Reward: 5.945. Training.\n",
            "[INFO] AgentBehavior. Step: 40000. Time Elapsed: 217.255 s. Mean Reward: -11.557. Std of Reward: 3.030. Training.\n",
            "[INFO] AgentBehavior. Step: 50000. Time Elapsed: 272.762 s. Mean Reward: -12.125. Std of Reward: 5.470. Training.\n",
            "[INFO] AgentBehavior. Step: 60000. Time Elapsed: 325.503 s. Mean Reward: -11.854. Std of Reward: 5.218. Training.\n",
            "[INFO] AgentBehavior. Step: 70000. Time Elapsed: 378.082 s. Mean Reward: -9.860. Std of Reward: 8.162. Training.\n",
            "[INFO] AgentBehavior. Step: 80000. Time Elapsed: 434.038 s. Mean Reward: -10.193. Std of Reward: 7.050. Training.\n",
            "[INFO] AgentBehavior. Step: 90000. Time Elapsed: 485.544 s. Mean Reward: -11.260. Std of Reward: 2.763. Training.\n",
            "[INFO] AgentBehavior. Step: 100000. Time Elapsed: 540.017 s. Mean Reward: -11.195. Std of Reward: 7.295. Training.\n",
            "[INFO] AgentBehavior. Step: 110000. Time Elapsed: 592.451 s. Mean Reward: -12.124. Std of Reward: 2.793. Training.\n",
            "[INFO] AgentBehavior. Step: 120000. Time Elapsed: 645.946 s. Mean Reward: -10.338. Std of Reward: 6.547. Training.\n",
            "[INFO] AgentBehavior. Step: 130000. Time Elapsed: 699.869 s. Mean Reward: -11.633. Std of Reward: 5.462. Training.\n",
            "[INFO] AgentBehavior. Step: 140000. Time Elapsed: 752.013 s. Mean Reward: -11.903. Std of Reward: 2.900. Training.\n",
            "[INFO] AgentBehavior. Step: 150000. Time Elapsed: 803.576 s. Mean Reward: -10.263. Std of Reward: 8.751. Training.\n",
            "[INFO] AgentBehavior. Step: 160000. Time Elapsed: 857.653 s. Mean Reward: -7.737. Std of Reward: 12.153. Training.\n",
            "[INFO] AgentBehavior. Step: 170000. Time Elapsed: 910.105 s. Mean Reward: -7.675. Std of Reward: 10.352. Training.\n"
          ]
        }
      ]
    }
  ]
}